{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88abfe4-b7b5-4557-964e-6af153f32155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import random\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import functools\n",
    "import yaml\n",
    "\n",
    "from dask_kubernetes import KubeCluster\n",
    "from joblib import Memory\n",
    "from dask.distributed import Client\n",
    "from calculator_upload import predict_E\n",
    "from ocpmodels.models.dimenet_plus_plus import DimeNetPlusPlusWrap\n",
    "\n",
    "import os\n",
    "\n",
    "from enumeration_helper_script import enumerate_surface_wrap\n",
    "from tqdm import tqdm\n",
    "from ocdata.adsorbates import Adsorbate\n",
    "from ocdata.bulk_obj import Bulk\n",
    "from ocdata.base_atoms.pkls import BULK_PKL, ADSORBATE_PKL\n",
    "\n",
    "\n",
    "\n",
    "# Initiate some helpful accessories\n",
    "#------------------------------------------------------------------------------\n",
    "name_to_num_dict = {1: 'H', 2: 'He', 3: 'Li', 4: 'Be', 5: 'B', 6: 'C', 7: 'N',\n",
    "                    8: 'O', 9: 'F', 10: 'Ne', 11: 'Na', 12: 'Mg', 13: 'Al', 14: 'Si',\n",
    "                    15: 'P', 16: 'S', 17: 'Cl', 18: 'Ar', 19: 'K', 20: 'Ca', 21: 'Sc',\n",
    "                    22: 'Ti', 23: 'V', 24: 'Cr', 25: 'Mn', 26: 'Fe', 27: 'Co', 28: 'Ni',\n",
    "                    29: 'Cu', 30: 'Zn', 31: 'Ga', 32: 'Ge', 33: 'As', 34: 'Se', 35: 'Br', \n",
    "                    36: 'Kr', 37: 'Rb', 38: 'Sr', 39: 'Y', 40: 'Zr', 41: 'Nb', 42: 'Mo',\n",
    "                    43: 'Tc', 44: 'Ru', 45: 'Rh', 46: 'Pd', 47: 'Ag', 48: 'Cd', 49: 'In',\n",
    "                    50: 'Sn', 51: 'Sb', 52: 'Te', 53: 'I', 54: 'Xe', 55: 'Cs', 56: 'Ba', \n",
    "                    57: 'La', 58: 'Ce', 59: 'Pr', 60: 'Nd', 61: 'Pm', 62: 'Sm', 63: 'Eu', \n",
    "                    64: 'Gd', 65: 'Tb', 66: 'Dy', 67: 'Ho', 68: 'Er', 69: 'Tm', 70: 'Yb',\n",
    "                    71: 'Lu', 72: 'Hf', 73: 'Ta', 74: 'W', 75: 'Re', 76: 'Os', 77: 'Ir', \n",
    "                    78: 'Pt', 79: 'Au', 80: 'Hg', 81: 'Tl', 82: 'Pb', 83: 'Bi', 84: 'Po',\n",
    "                    85: 'At', 86: 'Rn', 87: 'Fr', 88: 'Ra', 89: 'Ac', 90: 'Th', 91: 'Pa',\n",
    "                    92: 'U', 93: 'Np', 94: 'Pu', 95: 'Am', 96: 'Cm', 97: 'Bk', 98: 'Cf',\n",
    "                    99: 'Es', 100: 'Fm', 101: 'Md', 102: 'No', 103: 'Lr', 104: 'Rf',\n",
    "                    105: 'Db', 106: 'Sg', 107: 'Bh', 108: 'Hs', 109: 'Mt', 110: 'Ds', \n",
    "                    111: 'Rg', 112: 'Cn', 113: 'Nh', 114: 'Fl', 115: 'Mc', 116: 'Lv',\n",
    "                    117: 'Ts', 118: 'Og'}\n",
    "\n",
    "transition_metal1 =  list(range(21,31))\n",
    "transition_metal2 = list(range(39, 49))\n",
    "transition_metal3 = list(range(72, 80))\n",
    "transition_metals = [*transition_metal1, *transition_metal2, *transition_metal3]\n",
    "# you can set elements_to_include = transition_metals\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# INPUTS!!\n",
    "# ----------------------------------------------------------------------------\n",
    "# Bulk inputs\n",
    "mpids_to_slabs = True # True = use mpid_list to generate aslabs, False = use element list and num_of_els\n",
    "elements_to_include = [29]# list of desired atomic numbers\n",
    "mpid_list = ['mp-126']#,'mp-126','mp-74', 'mp-101', 'mp-124']\n",
    "num_of_els = [1] # [1,2] = unary and binary\n",
    "mpids_to_exclude = ['mp-672234', 'mp-632250', 'mp-754514', 'mp-570747', 'mp-12103', 'mp-25', \n",
    "                    'mp-672233', 'mp-568584', 'mp-154', 'mp-999498', 'mp-14', 'mp-96', 'mp-1080711', \n",
    "                    'mp-1008394', 'mp-22848', 'mp-160', 'mp-1198724'] #these are odd and cause failures\n",
    "\n",
    "# Adsorbate inputs\n",
    "adsorbates_smile_list = ['*H']\n",
    "\n",
    "# File paths\n",
    "config_path = '/home/jovyan/shared-scratch/Brook/ocpcalc_config.yml'\n",
    "worker_spec_path = '/home/jovyan/shared-scratch/Brook/worker-spec.yml'\n",
    "your_shared_scratch_path = '/home/jovyan/shared-scratch/Brook' # this will be used to create a cache dir in your folder\n",
    "\n",
    "# Other\n",
    "num_workers = 2 # should be scaled with workload. Use 1 to troubleshoot. 10 is a good place to start\n",
    "max_size = 100 # This is the maximum number of atoms you will allow in your slabs. Any greater will return size = Number rather than a prediction.\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pre-work / organization\n",
    "# -----------------------------------------------------------------------------\n",
    "# convert el nums to names\n",
    "elnames_to_include = [name_to_num_dict[el] for el in elements_to_include] \n",
    "\n",
    "# Process the checkpoint\n",
    "#  used to create a unique cache based on checkpoint\n",
    "with open(config_path) as f:\n",
    "            config = yaml.safe_load(f)\n",
    "checkpoint_path_dict = config['checkpoint_path']\n",
    "checkpoint_path = checkpoint_path_dict['path']\n",
    "cp_fn = checkpoint_path.split('/')\n",
    "cp_fn = cp_fn[-1]\n",
    "cp_fn = cp_fn.split('.')\n",
    "cp_fn = cp_fn[0]\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the workers\n",
    "# -----------------------------------------------------------------------------\n",
    "# Set the up a kube dask cluster \n",
    "cluster = KubeCluster(worker_spec_path, deploy_mode='local')\n",
    "cluster.adapt(minimum=2, maximum = num_workers, interval = '30000 ms')\n",
    "client = Client(cluster)\n",
    "\n",
    "def _worker_upload(dask_worker, *, data, fname):\n",
    "    dask_worker.loop.add_callback(\n",
    "    callback=dask_worker.upload_file,\n",
    "    comm=None,  # not used\n",
    "    filename=fname,\n",
    "    data=data,\n",
    "    load=True)\n",
    "\n",
    "## Upload code to every worker as they start/restart\n",
    "fname_ = ['enumeration_helper_script.py', 'calculator_upload.py']\n",
    "for fname in fname_:\n",
    "    with open(fname, 'rb') as f:\n",
    "        data = f.read()\n",
    "        client.register_worker_callbacks(\n",
    "            setup=functools.partial(\n",
    "                _worker_upload, data=data, fname=fname,\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Set up the cache directory - this will also be the local directory on each worker that will store cached results\n",
    "location_preds = your_shared_scratch_path + '/cachedir_predictions_mod_testing'+cp_fn\n",
    "location_slabs = your_shared_scratch_path + '/cachedir_slabs_testing'+cp_fn\n",
    "memory_preds = Memory(location_preds,verbose=1)\n",
    "memory_slabs = Memory(location_slabs,verbose=1)\n",
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73bd62-5aed-4e82-a740-91682ea2d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open pkl of bulks and their associated info\n",
    "with open(BULK_PKL, 'rb') as f:\n",
    "    inv_index = pickle.load(f)\n",
    "bulks = []\n",
    "\n",
    "# Grab the desired bulk atoms object\n",
    "if mpids_to_slabs:\n",
    "    num_of_els = [1,2,3]\n",
    "    for k in num_of_els:\n",
    "        for itm in inv_index[k]:\n",
    "            if itm[1] not in mpids_to_exclude and itm[1] in mpid_list:\n",
    "                 bulks.append(itm)\n",
    "else:\n",
    "    for k in num_of_els:\n",
    "        for itm in inv_index[k]: \n",
    "            els = itm[0].get_chemical_symbols() # Grab the chemical symbol of all\n",
    "            els = np.unique(els)\n",
    "            if itm[1] not in mpids_to_exclude and set(els).issubset(elnames_to_include):\n",
    "                bulks.append(itm)\n",
    "\n",
    "# Open pkl of adsorbates and grab info for the ones in the smile list         \n",
    "with open(ADSORBATE_PKL, 'rb') as f:\n",
    "    inv_index = pickle.load(f)\n",
    "ads_idx = [key for key in inv_index if inv_index[key][1] in adsorbates_smile_list]\n",
    "adsorbates_obj = [Adsorbate(ADSORBATE_PKL, specified_index = idx) for idx in ads_idx]\n",
    "\n",
    "\n",
    "#create a dask bag of adsorbates\n",
    "adsorbate_bag = db.from_sequence(adsorbates_obj)\n",
    "\n",
    "#create a dask bag of bulks\n",
    "bulk_bag = db.from_sequence(bulks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8434e2-cc71-4642-a3a6-0da1ded589c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the adslab mappings\n",
    "surfaces_bag = bulk_bag.map(memory_slabs.cache(enumerate_surface_wrap)).flatten()\n",
    "surface_ads_combos = surfaces_bag.product(adsorbate_bag).repartition(npartitions=num_workers*20).compute()\n",
    "surfaces = db.from_sequence(surface_ads_combos, npartitions=num_workers*20)\n",
    "# generate prediction mappings\n",
    "predictions_bag = surfaces.map(memory_preds.cache(predict_E), max_size)\n",
    "\n",
    "# execute operations (go to all work)\n",
    "predictions = predictions_bag.compute() # change to .compute() to push to local RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe3e7c-b9ed-4ddb-a1f3-2e20804ab140",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa546836-8e17-4de0-b66b-b5e119a44b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
